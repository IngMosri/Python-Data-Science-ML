
# ğŸ›’ Exploratory Data Analysis: Supermarket Sales

This repository is part of my **Data Science / Machine Learning learning journey with Python**.  
It demonstrates how to set up a clean, reproducible project in GitHub, configure virtual environments, and perform an initial **Exploratory Data Analysis (EDA)** on the **Sample Superstore dataset** using `pandas`, `matplotlib`, and `seaborn`.

---

## ğŸ“‚ Repository Structure

Python-Data-Science-ML/
â”‚
â”œâ”€â”€ data/              # local datasets (NOT pushed to GitHub, only .gitkeep placeholder)
â”œâ”€â”€ notebook_py/       # analysis scripts in .py format
â”‚   â””â”€â”€ test_env.py    # environment test script
â”‚   â””â”€â”€ eda_supermarket.py   # main EDA script
â”œâ”€â”€ figs/              # exported charts from EDA
â”œâ”€â”€ requirements.txt   # project dependencies
â””â”€â”€ README.md

---

## ğŸ“Š Dataset

- Source: [Kaggle â€” Sample Superstore](https://www.kaggle.com/datasets/roopacalistus/superstore)  
- Size: ~10,000 rows  
- Columns include:  
  - Categorical: `Ship Mode`, `Segment`, `Country`, `City`, `State`, `Region`, `Category`, `Sub-Category`  
  - Numerical: `Sales`, `Quantity`, `Discount`, `Profit`  

---

## âš™ï¸ Environment Setup

1. **Clone repository**
   ```bash
   git clone https://github.com/IngMosri/Python-Data-Science-ML.git
   cd Python-Data-Science-ML

	2.	Create and activate virtual environment

python -m venv .venv
source .venv/bin/activate    # macOS/Linux
.venv\Scripts\activate       # Windows


	3.	Install dependencies

pip install -r requirements.txt


	4.	Run environment test

python notebook_py/test_env.py

Output confirms Python path and versions of Pandas/Numpy.

â¸»

ğŸš€ How to Run the Analysis

From the project root:

python notebook_py/eda_supermarket.py

	â€¢	Generates multiple plots (each in a separate figure).
	â€¢	All plots are automatically exported to the figs/ folder.

â¸»

ğŸ“ˆ Example Outputs

Sales Distribution

Top 15 Cities by Sales

Discount vs Profit

Correlation Matrix


â¸»

âœ… Key Findings (Week 1)
	â€¢	No missing values in the dataset; data types are clean.
	â€¢	Technology is the leading category in sales.
	â€¢	New York City and Los Angeles dominate sales volume.
	â€¢	High discounts strongly reduce profit (negative correlation).

â¸»

ğŸ“Œ Progress Log
	â€¢	âœ”ï¸ Repo cleaned and reset (removed heavy files, added .gitignore).
	â€¢	âœ”ï¸ Configured .venv for Python 3.12.
	â€¢	âœ”ï¸ Added base dependencies: numpy, pandas, matplotlib, seaborn.
	â€¢	âœ”ï¸ Created requirements.txt for reproducibility.
	â€¢	âœ”ï¸ Tested environment with test_env.py.
	â€¢	âœ”ï¸ Implemented eda_supermarket.py with Markdown-style sections and clear plots.
	â€¢	âœ”ï¸ Added figs/ folder for chart exports.
	â€¢	âœ”ï¸ Updated README with structure, setup instructions, outputs, and findings.

â¸»

ğŸ¯ Next Steps
	â€¢	Week 2: Advanced data manipulation with groupby, pivot_table, and merges.
	â€¢	Improve visualizations (boxplots, pairplots, category breakdowns).
	â€¢	Document insights in README + prepare for first ML task.
